In SQL Server, **filegroups** are a mechanism that allows you to group one or more database files (data files) for easier management and allocation. They play a key role when it comes to **partitioning**, which is the practice of splitting large tables into smaller, manageable parts.

### 1. **Filegroups**

A **filegroup** is a logical grouping of one or more physical database files that make up a SQL Server database. By organizing files into filegroups, you can manage database storage in a more controlled manner.

- **Primary Filegroup**: The default filegroup in which system tables and the primary data file reside.
- **User-Defined Filegroups**: These are created by the database administrator to distribute database objects across different physical files.

### 2. **Partitioning in SQL Server**

Partitioning allows you to split large tables or indexes into smaller, more manageable parts called **partitions**. Each partition contains a portion of the data based on a partitioning scheme (e.g., date ranges, numerical ranges), which makes managing large datasets more efficient.

You can store partitions in different **filegroups** to distribute the data across multiple storage devices, improving performance and manageability.

### 3. **Combining Filegroups and Partitioning**

When you combine filegroups and partitioning, you can allocate different partitions to different filegroups, allowing better performance by distributing the load across different disks or drives.

### Example of Using Filegroups with Partitioning

#### Step 1: Creating Filegroups

First, we create additional filegroups that will hold the partitions of the table.

```sql
-- Create additional filegroups
ALTER DATABASE YourDatabase
ADD FILEGROUP Filegroup1;
ALTER DATABASE YourDatabase
ADD FILEGROUP Filegroup2;

-- Add files to the filegroups
ALTER DATABASE YourDatabase
ADD FILE (
    NAME = File1,
    FILENAME = 'C:\SQLData\Filegroup1.ndf',
    SIZE = 5MB,
    MAXSIZE = 100MB,
    FILEGROWTH = 5MB
) TO FILEGROUP Filegroup1;

ALTER DATABASE YourDatabase
ADD FILE (
    NAME = File2,
    FILENAME = 'D:\SQLData\Filegroup2.ndf',
    SIZE = 5MB,
    MAXSIZE = 100MB,
    FILEGROWTH = 5MB
) TO FILEGROUP Filegroup2;
```

- Here, two filegroups (`Filegroup1` and `Filegroup2`) are created and each is associated with a data file located on different disks.
  
#### Step 2: Creating a Partition Function

A **partition function** defines how the table’s rows will be split across partitions based on some column value (e.g., date, ID, etc.).

```sql
-- Create a partition function
CREATE PARTITION FUNCTION PartitionFunc(int)
AS RANGE LEFT FOR VALUES (10000, 20000, 30000);
```

This partition function will divide data based on the values of an integer column. For example:
- Rows with values less than or equal to `10000` go to the first partition.
- Rows with values less than or equal to `20000` go to the second partition, and so on.

#### Step 3: Creating a Partition Scheme

The **partition scheme** maps the partitions from the partition function to specific filegroups.

```sql
-- Create a partition scheme that maps partitions to filegroups
CREATE PARTITION SCHEME PartitionScheme
AS PARTITION PartitionFunc
TO (Filegroup1, Filegroup2, PRIMARY);
```

This scheme specifies that:
- Data in the first partition (values ≤ 10000) will be stored in `Filegroup1`.
- Data in the second partition (values ≤ 20000) will be stored in `Filegroup2`.
- Data in the third partition (values ≤ 30000) will be stored in the `PRIMARY` filegroup.

#### Step 4: Creating a Partitioned Table

Now we create a table that will be partitioned according to the partition scheme.

```sql
-- Create a partitioned table
CREATE TABLE Orders (
    OrderID INT,
    OrderDate DATE,
    CustomerID INT,
    Amount DECIMAL(10, 2)
)
ON PartitionScheme(OrderID);  -- Use the partition scheme for partitioning
```

This creates a partitioned table, where the rows are divided based on the `OrderID` column and stored in different filegroups according to the partition scheme.

#### Step 5: Inserting Data and Querying

```sql
-- Insert data into the partitioned table
INSERT INTO Orders (OrderID, OrderDate, CustomerID, Amount)
VALUES (5000, '2023-01-01', 101, 250.00),
       (15000, '2023-02-01', 102, 500.00),
       (25000, '2023-03-01', 103, 750.00);

-- Query to retrieve partition information
SELECT $PARTITION.PartitionFunc(OrderID) AS PartitionNumber, *
FROM Orders;
```

- The first row (`OrderID = 5000`) is stored in the first partition, which maps to `Filegroup1`.
- The second row (`OrderID = 15000`) is stored in the second partition, which maps to `Filegroup2`.
- The third row (`OrderID = 25000`) is stored in the third partition, which is in the `PRIMARY` filegroup.

### Benefits of Using Filegroups with Partitioning

1. **Performance**: Distributing large amounts of data across multiple filegroups that are placed on different disks can improve query performance by balancing the I/O load.
   
2. **Manageability**: You can backup and restore partitions independently. For example, if only one partition is corrupted, you can restore just the filegroup associated with that partition.

3. **Scalability**: Partitioning allows you to handle large datasets efficiently by splitting them into smaller chunks. Using filegroups helps with physical data distribution.

4. **Maintenance**: You can move old or less-frequently accessed partitions to slower or cheaper storage, while keeping more recent, frequently accessed partitions on faster disks.

### Summary

- **Filegroups** allow you to manage physical database files and distribute them across different storage devices.
- **Partitioning** enables you to split a large table into smaller parts (partitions) for performance and manageability.
- By using **filegroups with partitioning**, you can store different partitions in different filegroups, thereby improving performance by distributing data across multiple disks, while also simplifying maintenance tasks like backup and restore.

This approach is especially useful in large-scale systems where high data volume and performance are critical.